{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC \n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed_all(123)\n",
    "np.random.seed(123)\n",
    "torch.cuda.manual_seed_all(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_to_standard = {}\n",
    "original_to_standard[0]=0\n",
    "original_to_standard[0.25]=1\n",
    "original_to_standard[0.5]=2\n",
    "original_to_standard[0.75]=3\n",
    "original_to_standard[1]=4\n",
    "standard_to_original = {}\n",
    "standard_to_original[0]=0\n",
    "standard_to_original[1]=0.25\n",
    "standard_to_original[2]=0.5\n",
    "standard_to_original[3]=0.75\n",
    "standard_to_original[4]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data_electra(tokens, embeddings_dict, complexity):\n",
    "    x_train = []\n",
    "    for i in range(len(tokens)):\n",
    "        temp = np.array(embeddings_dict[tokens[i]])\n",
    "        x_train.append(temp)\n",
    "\n",
    "    x_train = np.array(x_train, dtype=np.float32)\n",
    "    y_train = complexity\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs(actual - pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x_train, y_train):\n",
    "    model = LinearRegression().fit(x_train, y_train)        \n",
    "    return model\n",
    "\n",
    "def predict(model, x):\n",
    "    predicted = model.predict(x)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Embeddings\n",
    "# Opening JSON file \n",
    "f = open('Embeddings/BERT_embeddings_sum.json') \n",
    "  \n",
    "# returns JSON object as a dictionary \n",
    "embeddings_dict1 = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Embeddings\n",
    "# Opening JSON file \n",
    "f = open('Embeddings/Electra_embeddings.json') \n",
    "  \n",
    "# returns JSON object as a dictionary \n",
    "embeddings_dict2 = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Embeddings\n",
    "# Opening JSON file \n",
    "f = open('Embeddings/glove_embeddings.json')\n",
    "# f = open('Embeddings/hand_crafted_features.json')\n",
    "# returns JSON object as a dictionary \n",
    "embeddings_dict3 = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Embeddings\n",
    "# Opening JSON file \n",
    "# f = open('Embeddings/glove_embeddings.json')\n",
    "f = open('Embeddings/hand_crafted_features.json')\n",
    "# returns JSON object as a dictionary \n",
    "embeddings_dict4 = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict4 = embeddings_dict3\n",
    "embeddings_dict1 = embeddings_dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(predictions):\n",
    "    predicted = (predictions[0]+predictions[1]+predictions[2]+predictions[3]+predictions[4])/5\n",
    "#     predicted = predictions[0]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_util(df, embeddings_dict):\n",
    "    tokens = df['id'].values\n",
    "    complexity = df['complexity'].values\n",
    "\n",
    "    x_train, y_train = get_train_data_electra(tokens, embeddings_dict, complexity)\n",
    "    model = training(x_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_util(df, model, embeddings_dict):\n",
    "    tokens = df['id'].values\n",
    "    complexity = df['complexity'].values\n",
    "\n",
    "    x_test, y_test = get_train_data_electra(tokens, embeddings_dict, complexity)\n",
    "    return predict(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_annotations(df,n=20):   \n",
    "    scores = df['complexity']\n",
    "    annotations = []\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i]>=0 and scores[i]<0.25:\n",
    "            low = 0\n",
    "            high = 0.25\n",
    "        elif scores[i]>=0.25 and scores[i]<0.5:\n",
    "            low = 0.25\n",
    "            high = 0.5\n",
    "        elif scores[i]>=0.5 and scores[i]<0.75:\n",
    "            low = 0.5\n",
    "            high = 0.75\n",
    "        elif scores[i]>=0.75 and scores[i]<1:\n",
    "            low = 0.75\n",
    "            high = 1\n",
    "        alpha = (high - scores[i])/(high-low)\n",
    "        num_low = int(np.floor(alpha*n))\n",
    "        num_high = n - num_low\n",
    "\n",
    "        temp = int(original_to_standard[high])*np.ones(n,dtype=int)\n",
    "        for i in range(num_low):\n",
    "            temp[i]=int(original_to_standard[low])\n",
    "        annotations.append(temp.tolist())\n",
    "    #     print(num_low, num_high)\n",
    "    annotations = np.array(annotations)\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def zscore(x, m, s):\n",
    "    for i in range(len(x[0,:])):\n",
    "        x[:,i] = (x[:,i] - m[i])/s[i]\n",
    "    return x\n",
    "\n",
    "def getx_train(tokens, embeddings_dict):\n",
    "    x_train = []\n",
    "    for i in range(len(tokens)):\n",
    "        temp = np.array(embeddings_dict[tokens[i]])\n",
    "        x_train.append(temp)\n",
    "\n",
    "    x_train = np.array(x_train, dtype = np.float32)\n",
    "    return x_train\n",
    "\n",
    "def classification(x, y):   \n",
    "#     clf = SVC(kernel = 'linear', verbose=1, C = 1).fit(x, y) \n",
    "    clf = SVC(kernel = 'rbf', verbose=1,C = 1).fit(x, y)\n",
    "#     clf = SVC(kernel = 'sigmoid', verbose=1, C = 1).fit(x, y)\n",
    "#     clf = RandomForestClassifier(max_depth = 18, verbose=1).fit(x, y)\n",
    "#     clf = KNeighborsClassifier(n_neighbors = 5, verbose=1).fit(x, y) \n",
    "#     clf = LogisticRegression(random_state=0, verbose=1).fit(x, y)\n",
    "#     gnb = GaussianNB(verbose=1).fit(x, y) \n",
    "    \n",
    "    return clf\n",
    "\n",
    "def predict(clf, x):\n",
    "    return clf.predict(x)\n",
    "\n",
    "def mae(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs(actual - pred))\n",
    "\n",
    "def train_test2(df_train,df_test, embeddings_dict1, n=20):\n",
    "    annotations = generate_annotations(df_train,n)\n",
    "    x_train = getx_train(df_train['id'], embeddings_dict1)\n",
    "    x_test = getx_train(df_test['id'], embeddings_dict1)\n",
    "    predictions = []\n",
    "    for i in range(n):\n",
    "        y_train = annotations[:,i]\n",
    "        model = classification(x_train, y_train)\n",
    "        predictions.append(predict(model,x_test))\n",
    "    y_test = df_test['complexity']\n",
    "    \n",
    "    pred = np.array(predictions, dtype = float)\n",
    "    for i in range(len(pred)):\n",
    "        for j in range(len(pred[i])):\n",
    "            pred[i,j]=standard_to_original[int(pred[i,j])]\n",
    "            \n",
    "    y_pred = np.zeros(y_test.shape,dtype=float)\n",
    "    for j in range(len(y_test)):\n",
    "        y_pred[j] = pred[:,j].mean()\n",
    "    \n",
    "    return y_pred\n",
    "#     return mae(y_test, y_pred)\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df_train,df_test, embeddings_dict1, embeddings_dict2, embeddings_dict3):\n",
    "    # Training BERT Model\n",
    "    model1 = training_util(df_train, embeddings_dict1)\n",
    "    # Training Electra Model\n",
    "    model2 = training_util(df_train, embeddings_dict2)\n",
    "    # Training Glove Model\n",
    "    model3 = training_util(df_train, embeddings_dict3)\n",
    "    # Training HC Model\n",
    "    model4 = training_util(df_train, embeddings_dict4)\n",
    "        \n",
    "    # Testing on All\n",
    "    df = df_test\n",
    "    tokens = df['id'].values\n",
    "    complexity = df['complexity']\n",
    "    x_test, y_test = get_train_data_electra(tokens, embeddings_dict1, complexity)\n",
    "\n",
    "    predictions = []\n",
    "# Regression\n",
    "    # BERT\n",
    "#     predictions.append(testing_util(df, model1, embeddings_dict1))\n",
    "\n",
    "    # Electra\n",
    "    predictions.append(testing_util(df, model2, embeddings_dict2))\n",
    "\n",
    "    # Glove\n",
    "#     predictions.append(testing_util(df, model3, embeddings_dict3))\n",
    "    \n",
    "    \n",
    "# Classification\n",
    "    \n",
    "#     predictions.append(train_test2(df_train,df_test, embeddings_dict2, 30))\n",
    "    \n",
    "    predictions.append(train_test2(df_train,df_test, embeddings_dict3, 50))\n",
    "    \n",
    "    # HC\n",
    "#     predictions.append(testing_util(df, model4, embeddings_dict4))\n",
    "    \n",
    "#     predictions.append(train_test2(df_train,df_test, embeddings_dict4, 30))\n",
    "    \n",
    "    return predictions, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]0.015045486590789477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# # Single Words\n",
    "\n",
    "# df_train = pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_train.tsv\",\n",
    "#                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "# df1 = df_train.sample(frac=1,random_state=2)\n",
    "# df2 = df1[df1['corpus']!='europarl']\n",
    "# df3 = df1[df1['corpus']=='europarl']\n",
    "# df_train = df2\n",
    "# df_train = df_train.append(df3.sample(frac=0.5,random_state=2))\n",
    "\n",
    "# # df_train = df_train.append(pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_trial.tsv\",\n",
    "# #                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8'))\n",
    "# df_curr = pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_train.tsv\",\n",
    "#                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8').sample(frac=1,random_state=2)\n",
    "# df_train = df_train.append(df_curr[df_curr['corpus']!='europarl'])\n",
    "\n",
    "# df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "# df_test = pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_trial.tsv\",\n",
    "#                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "\n",
    "\n",
    "# # df_test = pd.read_csv(\"Group 1 Dataset/LCP_Single/test1.csv\")\n",
    "# df_test['complexity'] = 0.00000\n",
    "\n",
    "# predictions, y_test = train_test(df_train,df_test, embeddings_dict1, embeddings_dict2, embeddings_dict3)\n",
    "\n",
    "# # y_pred = (predictions[0]+predictions[1]+predictions[2]+predictions[3]+predictions[4])/5\n",
    "\n",
    "# # y_pred = (predictions[0]+predictions[1])/2\n",
    "\n",
    "# y = pd.read_csv('Group 1 Dataset/Sagnik/1_layer_trainable96.csv',header = None)\n",
    "\n",
    "# # y_pred = 0.6*x[1]+0.4*y[1]\n",
    "# y_pred = 0.5*predictions[1]+0.5*y[1]\n",
    "# y_pred = list(y_pred)\n",
    "\n",
    "# print(scipy.stats.pearsonr(pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_trial.tsv\",\n",
    "#                                   delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')['complexity'],y_pred))\n",
    "\n",
    "# df_test['Predicted Complexity'] = 0.00000\n",
    "# for i in range(len(df_test)):\n",
    "#     df_test['Predicted Complexity'][i] = y_pred[i]\n",
    "\n",
    "# # df_final = df_test.drop(columns=['complexity','subcorpus','sentence','token'])\n",
    "\n",
    "# # print(mae(pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_trial.tsv\",\n",
    "# #                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')['complexity'],y_pred))\n",
    "\n",
    "# # print(scipy.stats.pearsonr(pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_trial.tsv\",\n",
    "# #                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')['complexity'],y_pred))\n",
    "\n",
    "# df_final = df_test.drop(columns=['complexity','subcorpus','sentence','token'])\n",
    "# df_final.to_csv('single_trial_predictions.csv',index=False, header=None)\n",
    "\n",
    "# Single Words\n",
    "df_train = pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_train.tsv\",\n",
    "                              delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "\n",
    "df_train = df_train.append(pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_trial.tsv\",\n",
    "                              delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8'))\n",
    "\n",
    "df_curr = pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_train.tsv\",\n",
    "                              delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8').sample(frac=1,random_state=2)\n",
    "df_train = df_train.append(df_curr)\n",
    "# [df_curr['corpus']!='europarl'])\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "df_test = pd.read_csv(\"Group 1 Dataset/Test/lcp_single_test.tsv\",\n",
    "                              delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "\n",
    "df_test['complexity'] = 0.00000\n",
    "\n",
    "predictions, y_test = train_test(df_train,df_test, embeddings_dict1, embeddings_dict2, embeddings_dict3)\n",
    "\n",
    "y = pd.read_csv('Group 1 Dataset/Sagnik/1_layer_trainable_trainandtrial_test_96.csv',header = None)\n",
    "\n",
    "y_pred = 0.5*predictions[1]+0.5*y[1]\n",
    "y_pred = list(y_pred)\n",
    "\n",
    "df_test['Predicted Complexity'] = 0.00000\n",
    "for i in range(len(df_test)):\n",
    "    df_test['Predicted Complexity'][i] = y_pred[i]\n",
    "\n",
    "df_final = df_test.drop(columns=['complexity','corpus','sentence','token'])\n",
    "df_final.to_csv('single_test_predictions_3.csv',index=False,header=None)\n",
    "df_final = df_test.drop(columns=['complexity'])\n",
    "df_final.to_csv('single_test_predictions_temp_3.csv',index=False,header=None)\n",
    "\n",
    "print(mae(pd.read_csv('single_test_predictions_1.csv',header = None)[1],pd.read_csv('single_test_predictions_3.csv',header = None)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]0.013234233026919154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# # MWEs\n",
    "\n",
    "# df_train = pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_train.tsv\",\n",
    "#                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "# # df_train = df_train.append(pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_trial.tsv\",\n",
    "# #                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8'))\n",
    "# df_curr = pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_train.tsv\",\n",
    "#                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8').sample(frac=1,random_state=2)[:2073]\n",
    "# df_train = df_train.append(df_curr[df_curr['corpus']!='europarl'])\n",
    "# # df_train = df_train.append(pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_trial.tsv\",\n",
    "# #                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8'))\n",
    "# # df_train = df_train.append(df_temp[df_temp['corpus']=='biomed'])\n",
    "# df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "# # df_train = pd.read_csv(\"Group 1 Dataset/LCP_Multi/trainfinal.csv\")\n",
    "# df_test = pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_trial.tsv\",\n",
    "#                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "# df_test['complexity'] = 0.00000\n",
    "\n",
    "# predictions, y_test = train_test(df_train,df_test, embeddings_dict1, embeddings_dict2, embeddings_dict3)\n",
    "\n",
    "# # y_pred = (predictions[0]+predictions[1]+predictions[2]+predictions[3]+predictions[4]+predictions[5]+predictions[6])/7\n",
    "# # y_pred = (predictions[0]+predictions[1]+predictions[2]+predictions[3]+predictions[4])/5\n",
    "\n",
    "# y_pred = (predictions[0]+predictions[1])/2\n",
    "\n",
    "\n",
    "# df_test['Predicted Complexity'] = 0.00000\n",
    "\n",
    "# for i in range(len(df_test)):\n",
    "#     df_test['Predicted Complexity'][i] = y_pred[i]\n",
    "\n",
    "# df_final = df_test.drop(columns=['complexity','subcorpus','sentence','token'])\n",
    "\n",
    "# # print(mae(pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_trial.tsv\",\n",
    "# #                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')['complexity'],y_pred))\n",
    "\n",
    "# print(scipy.stats.pearsonr(pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_trial.tsv\",\n",
    "#                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')['complexity'],y_pred))\n",
    "# df_final = df_test.drop(columns=['complexity','subcorpus','sentence','token'])\n",
    "# df_final.to_csv('multi_trial_predictions.csv',index=False,header=None)\n",
    "\n",
    "# MWEs\n",
    "df_train = pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_train.tsv\", \n",
    "                       delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "df_train = df_train.append(pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_trial.tsv\",\n",
    "                              delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8'))\n",
    "df_curr = pd.read_csv(\"Group 1 Dataset/Dataset 1/lcp_single_train.tsv\",\n",
    "                              delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8').sample(frac=1,random_state=2)[:1900]\n",
    "df_train = df_train.append(df_curr)\n",
    "# [df_curr['corpus']!='europarl'])\n",
    "# df_train = df_train.append(pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_trial.tsv\",\n",
    "#                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8'))\n",
    "# df_train = df_train.append(df_temp[df_temp['corpus']=='biomed'])\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "# df_train = pd.read_csv(\"Group 1 Dataset/LCP_Multi/trainfinal.csv\")\n",
    "df_test = pd.read_csv(\"Group 1 Dataset/Test/lcp_multi_test.tsv\",\n",
    "                              delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "df_test['complexity'] = 0.00000\n",
    "\n",
    "predictions, y_test = train_test(df_train,df_test, embeddings_dict1, embeddings_dict2, embeddings_dict3)\n",
    "\n",
    "y_pred = (predictions[0]+predictions[1])/2\n",
    "\n",
    "df_test['Predicted Complexity'] = 0.00000\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    df_test['Predicted Complexity'][i] = y_pred[i]\n",
    "\n",
    "#     df_final = df_test.drop(columns=['complexity','corpus','sentence','token'])\n",
    "\n",
    "# print(mae(pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_trial.tsv\",\n",
    "#                               delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')['complexity'],y_pred))\n",
    "\n",
    "#     print(scipy.stats.pearsonr(pd.read_csv(\"Group 1 Dataset/Dataset 2/lcp_multi_trial.tsv\",\n",
    "#                                   delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')['complexity'],y_pred))\n",
    "df_final = df_test.drop(columns=['complexity','corpus','sentence','token'])\n",
    "df_final.to_csv('multi_test_predictions_3.csv',index=False,header=None)\n",
    "df_final = df_test.drop(columns=['complexity'])\n",
    "df_final.to_csv('multi_test_predictions_temp_3.csv',index=False,header=None)\n",
    "    \n",
    "print(mae(pd.read_csv('multi_test_predictions.csv',header = None)[1],pd.read_csv('multi_test_predictions_3.csv',header = None)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
